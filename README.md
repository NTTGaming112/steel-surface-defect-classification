# Steel Surface Defect Detection

Dá»± Ã¡n phÃ¡t hiá»‡n khuyáº¿t táº­t bá» máº·t thÃ©p sá»­ dá»¥ng Computer Vision vÃ  Machine Learning vá»›i nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau.

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
project/
â”œâ”€â”€ data/              # Dá»¯ liá»‡u thÃ´ (NEU-DET)
â”œâ”€â”€ models/            # CÃ¡c mÃ´ hÃ¬nh ML Ä‘Ã£ train (SVM, RF, KNN)
â”œâ”€â”€ checkpoints/       # Trá»ng sá»‘ cá»§a cÃ¡c mÃ´ hÃ¬nh
â”œâ”€â”€ demo/              # á»¨ng dá»¥ng web Gradio
â”œâ”€â”€ notebooks/         # Jupyter notebooks (EDA, thá»­ nghiá»‡m)
â”œâ”€â”€ docs/              # TÃ i liá»‡u
â””â”€â”€ README.md
```

## ğŸ“‹ MÃ´ táº£

Há»‡ thá»‘ng phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i 6 loáº¡i khuyáº¿t táº­t trÃªn bá» máº·t thÃ©p:

- Crazing
- Inclusion
- Patches
- Pitted Surface
- Rolled-in Scale
- Scratches

## ğŸ¯ Dataset

**NEU Surface Defect Database**

- Training: 1440 áº£nh (240 áº£nh/class Ã— 6 classes)
- Validation: 360 áº£nh (60 áº£nh/class Ã— 6 classes)
- Tá»•ng: 1800 áº£nh
- KÃ­ch thÆ°á»›c: 200x200 pixels (grayscale sau preprocessing)

## ğŸš€ Models

Chi tiáº¿t vá» quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  káº¿t quáº£ cá»§a tá»«ng mÃ´ hÃ¬nh cÃ³ trong cÃ¡c notebooks tÆ°Æ¡ng á»©ng:

- **SVM (Support Vector Machine)**: `notebooks/support-vector-machine.ipynb`
- **Random Forest**: `notebooks/random-forest.ipynb`
- **KNN (K-Nearest Neighbors)**: `notebooks/k-nearest-neighbor.ipynb`

Káº¿t quáº£ dÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» hiá»‡u suáº¥t tá»‘t nháº¥t Ä‘áº¡t Ä‘Æ°á»£c trong cÃ¡c thá»­ nghiá»‡m.

## ğŸ”§ Feature Extraction

### SIFT (Scale-Invariant Feature Transform)

- Sá»­ dá»¥ng Bag of Visual Words vá»›i cÃ¡c kÃ­ch thÆ°á»›c vocabulary khÃ¡c nhau (vÃ­ dá»¥: 100, 200).
- DÃ¹ng MiniBatchKMeans Ä‘á»ƒ táº¡o vocabulary.

### LBP (Local Binary Pattern)

- Thá»­ nghiá»‡m vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p LBP khÃ¡c nhau (`default`, `uniform`).
- TrÃ­ch xuáº¥t histogram tá»« áº£nh LBP.

### Preprocessing

- Cáº£i thiá»‡n Ä‘á»™ tÆ°Æ¡ng pháº£n vá»›i CLAHE (clipLimit=2.0, tileGridSize=8x8).
- Thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh vá» 200x200.
- Chuyá»ƒn Ä‘á»•i sang áº£nh xÃ¡m.

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
pip install -r requirements.txt
```

## ğŸ® Sá»­ dá»¥ng

### 1. Training Models

Má»Ÿ vÃ  cháº¡y cÃ¡c notebooks trong thÆ° má»¥c `notebooks/` Ä‘á»ƒ huáº¥n luyá»‡n láº¡i cÃ¡c mÃ´ hÃ¬nh:

- `support-vector-machine.ipynb`
- `random-forest.ipynb`
- `k-nearest-neighbor.ipynb`

### 2. Web Demo

Äá»ƒ cháº¡y á»©ng dá»¥ng demo, di chuyá»ƒn vÃ o thÆ° má»¥c `demo` vÃ  cháº¡y file `app.py`:

```bash
cd demo
python app.py
```

Truy cáº­p: http://127.0.0.1:7860

## ğŸ¨ Web Interface Features

- ğŸ“¤ Táº£i lÃªn áº£nh khuyáº¿t táº­t.
- ğŸ” Hiá»ƒn thá»‹ áº£nh sau khi tiá»n xá»­ lÃ½.
- ğŸ¯ 3 dá»± Ä‘oÃ¡n hÃ ng Ä‘áº§u vá»›i Ä‘iá»ƒm tin cáº­y.
- ğŸ“Š Báº£ng káº¿t quáº£ chi tiáº¿t.
- ğŸ¨ Giao diá»‡n tÃ¹y chá»‰nh.

**Note**:

- Táº¥t cáº£ models sá»­ dá»¥ng combined features (SIFT BoVW 100 + LBP 64 = 164 features)
- Training set: 1440 samples, Test set: 360 samples
- Hyperparameter optimization: Optuna vá»›i TPE Sampler

## ğŸ”¬ Hyperparameter Optimization

Sá»­ dá»¥ng **Optuna** vá»›i:

- 1000 trials cho má»—i feature set
- 3-fold cross-validation
- TPE Sampler
- Automatic checkpoint saving

## ğŸ“ Notes

- Táº¥t cáº£ models sá»­ dá»¥ng StandardScaler
- SIFT extractor Ä‘Æ°á»£c save Ä‘á»ƒ inference

## ğŸ“„ License

MIT License
